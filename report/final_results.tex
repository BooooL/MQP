\subsection{Full System Operation}
After fully testing each of the individual sensors used in this project and developing a working disparity algorithm, the individual modules created for each test were combined. The result of this finalized implementation was a proof of concept SLAM implementation capable of generating compass-reference 2D floorplans of its surroundings, as well as 3D depth maps of its entire field of view. The output modes of this device were user-selectable, and could be viewed on an external VGA display.
\par
An overall system block diagram of the final implementation of this project is shown in Figure \ref{systemBD2}. The programmable hardware version of this implementation may be found in Figure \ref{finalBD}. This implementation was broken down into several major components. At the top level, several blocks were used to connect the Zynq7 ARM Cortex A9 processing system to customized programmable logic using an AXI peripheral controller, as well as to peripherals such as the rangefinder and IMU using EMIO-GPIO and SPI-GPIO. At a high level, these connections allowed 
\par
\begin{figure}[H] 
	\centerline{
	\includegraphics[width=1.25\linewidth]{full_blockdiag.png}
	}
	\caption{Final System Block Diagram}
	\label{systemBD2}
\end{figure}
\par
\begin{figure}[!htb] 
	\centerline{
	\includegraphics[width=1.25\linewidth, angle=90]{final_bd.png}
	}
	\caption{Implemented Design}
	\label{finalBD}
\end{figure}
\par
The final hardware implementation of the project can be seen in Figure 
\ref{finalHW}. This implementation supported several output modes based on the positions of the user switches, including a 3D disparity mode, camera image mode, rangefinder output mode, and combined 2D "floorplan" mode. Note that the VGA outputs of each mode were continuously updated. 
\begin{figure}[H]  
 	\centerline{
	\includegraphics[width=1\linewidth]{setup_label.JPG}
	}
	\caption{System Hardware}
	\label{finalHW}
\end{figure}
\par
In order to create a fully integrated hardware-software interface that would allow for communication between the Zynq FPGA fabric and ARM processor, a customized IP core needed to be created. This issue was resolved by placing all programmable logic for the rangefinder, IMU, and camera interface into a user-generated IP core. named "custom logic", as shown in Figure \ref{finalBD}. The IP core was connected directly to the stereo camera breakout board, and accepted rangefinder and IMU data from the programmable software via an AXI interface. This customized IP core also accepted user inputs through the ZedBoard's switches, and supported outputs to the ZedBoard's LEDs and VGA interface. 
\par
The 3D disparity output mode may be found in Figure \ref{disparityOutputs}a. In this mode, a windowed 384x288 pixel depth map was continuously updated to reflect the camera's current field of view. Figure \ref{disparityOutputs}b shows a modified version of this output consisting of depth information from a centrally-located horizontal line of pixels from this depth map that may then be correlated with data from the scanning laser rangefinder. 
\par
\begin{figure}[H] 
         \begin{subfigure}[h]{0.5\textwidth}
              \centerline{\includegraphics[width=1.0\textwidth]{disparity_mode.JPG}}
             \caption{Full Output}
         \end{subfigure}
         \begin{subfigure}[h]{0.5\textwidth}
             \centerline{\includegraphics[width=1.0\textwidth]{disparity_line_mode.JPG}}
             \caption{Single Line Output}
         \end{subfigure}
\caption{Disparity Output Modes}
\label{disparityOutputs}
\end{figure}
\par
In order to aid in hardware debugging, an additional output mode was also included for showing the current camera images being used by the disparity algorithm, as shown in Figure \ref{camOutMode}. Note that the images captured were monochrome, and were arbitrarily mapped to VGA colors due to a lack of grayscale color space.
\par
\begin{figure}[H]  
 	\centerline{
	\includegraphics[width=0.5\linewidth]{camera_mode.JPG}
	}
	\caption{Raw Camera Data Mode}
	\label{camOutMode}
\end{figure} 
\par
The normal rangefinder output mode is shown in Figure \ref{rangeOutputs}a. In this mode, objects found by the scanning laser rangefinder were displayed in black. The entire scan was also referenced to the device's central location, shown in red. All rangefinder data was pre-processed by the programmable software to include a compass offset from the IMU, with due north representing the center of the top of the VGA display.
\par 
A final output mode was also included to incorporate disparity data with the 2D "floorplan" produced by the rangefinder. By combining data from both sensors, the stereo cameras were able to account for situations where the scanning laser rangefinder was out of range due to its limitations on viewing distance. This output mode is shown in Figure \ref{rangeOutputs}b.

\begin{figure}[H] 
         \begin{subfigure}[h]{0.5\textwidth}
              \centerline{\includegraphics[width=1.0\textwidth]{rangefinder_mode.JPG}}
             \caption{Rangefinder Output}
         \end{subfigure}
         \begin{subfigure}[h]{0.5\textwidth}
             \centerline{\includegraphics[width=1.0\textwidth]{combined_mode.JPG}}
             \caption{Combined Output}
         \end{subfigure}
\caption{2D "Floorplan" Output Modes}
\label{rangeOutputs}
\end{figure}
