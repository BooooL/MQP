This project demonstrated a proof of concept SLAM sensor suite as an effective replacement for the simple camera image sensors available on existing remote situational awareness products. Through the use of a stereo camera pair, scanning laser rangefinder,  digital compass, and Zynq-7000 All Programmable SoC, an all-in-one sensor suite was developed for capturing continuous localization and depth data on its surroundings. This sensor suite supported three main output modes that each displayed different localization information to an attached VGA display.
\par
A compass-referenced real-time 2D floorplan mode was created by using a scanning laser rangefinder to map the objects closest to the sensor suite. The rangefinder and digital compass modules were connected directly to the dual-core ARM Cortex A9 processor of the Zynq SoC, and were communicated with using low-level peripheral controls. Data collected from these sensors was combined and written to the FPGA fabric of the Zynq SoC, where a coordinate-axis transformation was used to localize distance data and prepare it for output via VGA display.
\par
As an accompaniment to the 2D floorplan mode, a disparity depth mapping mode was also created. This operating mode relied on a stereo camera pair. In order to minimize costs, a printed circuit board was designed that connected two camera modules and video frame buffer ICs to the FPGA fabric of the Zynq SoC. Using this interface, programmable logic was able to read image data from the circuit board’s frame buffers and trigger new image captures. After acquiring stereo camera image data, a Sum of Absolute Differences block matching algorithm was used to calculate depth measurements on a pixel by pixel basis throughout the scene. This depth information was then exported as-is in the form of a 3D disparity image.
\par
A final output mode was included to incorporate slices of disparity data into the 2D floorplan. Since the rangefinder and stereo cameras shared a horizontal viewing plane, there were some distinguishable overlaps in sensor data. These overlaps were correlated by filtering several horizontal lines of depth information from the disparity algorithm and combining them with 2D rangefinder data at the output stage. The resultant floorplan matched stereo camera depth data with rangefinder distance data, and allowed for compensation between measurement methods.
\par
Each of the three main output modes of this device allowed for a more complete understanding of its surroundings. This sensor suite demonstrated that FPGA-based data processing was a viable replacement for the simple imaging sensors of existing remote situational awareness products, and serves as an excellent platform for future development.

\subsection{Future Work}
The utility of this sensor suite could be increased by adding additional image processing algorithms for human recognition and object detection.  In a first responder situation, human recognition could be used to provide potentially life-saving information about where persons of interest are located. This feature could be added through the use of Xilinx’s High Level Synthesis environment, which would allow for the creation of programmable hardware from a powerful C/C++ image processing library such as Open Computer Vision (OpenCV).
\par
A simpler improvement could be to incorporate all available inertial displacement data into the device’s processing pipeline. With inertial displacement data completely integrated, this sensor suite would have the capability to produce a more sophisticated 2D map showing the complete path traversed by the device. This functionality would allow for a more complete understanding of the environment around the device.
\par
One other important step in the future of this design would be to combine all hardware used onto a single platform such as a printed circuit board. This board would contain a Zynq chip, an onboard IMU, and mounted stereo camera and rangefinder hardware. With the creation of a customized sensor board, the device could then be added to existing robotic platforms for field testing. 