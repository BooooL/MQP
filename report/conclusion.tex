\subsection{Summary of Progress}
This project demonstrates a proof of concept SLAM sensor suite that could be used as a cost-effective replacement for the simple camera image sensors available on existing remote mapping robotic products. Through the use of a stereo camera pair, scanning laser rangefinder, inertial measurement unit, and Zynq7020 All Programmable SoC, an all-in-one sensor suite was developed that is capable of capturing 2D and 3D dimensionality data on its surroundings. This sensor suite is unique in that it is able to process all of its data locally, without the need for additional processing power from the end user.
\par
On the input stage of the sensor platform, the scanning laser rangefinder and IMU module are connected directly to the dual-core ARM Cortex A9 processor of the Zynq SoC, and are communicated with using low-level peripheral controls. Data collected from each sensor is passed to the FPGA fabric of the Zynq SoC, where a coordinate-axis transform is used to localize rangefinder data based on IMU readings and prepare it for output via VGA display. In addition, a custom made printed circuit board is also used to connect two camera modules and attached image buffer ICs to the FPGA fabric of the Zynq SoC. After acquiring stereo camera image data, a Sum of Absolute Differences block matching algorithm is used to convert said data to depth measurements on a pixel by pixel basis. This depth information may then be exported as-is in the form of a 3D depth map, or in slices combined with rangefinder and IMU data to form a 2D floorplan of the area being observed by the sensor suite. The outputs of this platform demonstrate that FPGA-based data processing is a viable replacement for the simple imaging sensors of existing remote mapping products. 
\par
At the time of submission, the rangefinder, camera, and IMU interfaces and processing stages described have been fully implemented and tested in both hardware and various forms of simulation. This project was completed over a shortened timeline, and a larger portion of this time was dedicated to debugging hardware issues than originally expected. Due to a limited project budget of \$250, a customized stereo camera interface PCB with attached frame buffer ICs was developed as a low-cost alternative to existing commercial products. Several issues were encountered with the physical hardware of this interface, and this resulted in lost development time. 
\par
Issues were also encountered with finding a proper method of communicating with the scanning laser rangefinder, as the rangefinder and ZedBoard Zynq evaluation platform used two different logic voltage levels in their UART communications.  After successfully resolving these issues using a RS232-TTL logic-level converter, development began on integrating data from the inertial measurement unit into the rangefinder interface. After several weeks of unsuccessful communications and debugging with the original IMU intended for use in the project, it was determined that the unit was non-functional. A replacement unit relying on a different IMU sensor was eventually acquired in the final week of development, and little time was left for integrating IMU data into the sensor suite's overall implementation.
\par
Although the issues mentioned resulted in large delays in development, the proof of concept SLAM sensor suite created through this project serves as a excellent platform for future development. The implications of the hardware issues faced in this project were quickly realized, and some recommendations for future work may be based off of original project goals that were modified as a result of time constraints.

\subsection{Future Work}
For this sensor suite to be utilized to its maximum potential, additional image processing algorithms should be implemented to allow for human recognition and object detection. In a first responder situation, human recognition could be used to provide potentially life-saving information about where people are located. With additional IMU data completely integrated, this sensor suite also has the capability to produce a sophisticated 2D map with both the sensor suite's displacement and rotational data, and can even be combined with the stereo cameras' depth and human detection information. This functionality would allow for a near-complete understanding of the environment around the device.
\par
In order for the sensor suite's information to be useful to first responders, it needs to be accessible via wireless transmission. With wireless data transmission, not only is the system unrestricted by a physical connection, but the data can also be accessible to numerous devices at the same time. Since the sensor suite also processes its data locally, the information transmitted would be accessible to a wide range of low-power electronics without any major processing requirement.
\par
To reduce overall size and cost of the system, the completed design could use an integrated printed circuit board containing a Zynq chip, an onboard IMU, and mounted stereo camera hardware. With the creation of a customized sensor board, this project could truly serve its purpose as a durable replacement sensor suite for a wide range of robotic platforms currently used for remote observation and mapping. 




