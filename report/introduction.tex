\section{Introduction}
Currently there are many applications that rely on a simple video camera setup in order to gather information on remote and inaccessible locations. Although this is an effective strategy for simple surveillance, it is limited in many ways. Using current imaging and sensor technology, it is possible to gather 3D depth information on a given area as both a cost-effective and information-rich alternative to using a simple camera module on a device. Such a product would be able to implement high speed data processing techniques that allow for the creation of an augmented real-time video feed.
\par
This type of technology is known as Simultaneous Localization And Mapping, or SLAM. The purpose of SLAM is to compute the location of an agent within its environment, and allow for the creation of self-aware robot systems that are able to respond to their surroundings. SLAM is a common area of research in the field of image processing and high-speed computing, and has been applied mainly to autonomous vehicles. We would like to propose the creation of a SLAM-like system that is capable of monitoring and mapping its environment in real-time, which could be combined with the ability to detect and localize objects such as human beings. For the scope of this project, we would like to define our desired objective as Real-Time Remote Mapping, and will be focusing on the mapping portion of the proposed system.
\par
A device that is capable of mapping its surroundings using real-time SLAM is applicable to many different fields. The proposed system could be designed as a sensor suite capable of performing these tasks, intended to replace standard video cameras on existing robotic systems. This type of technology allows for people such as first responders to wirelessly traverse dangerous and remote locations in search of people in need. The envisioned sensor suite will be able to provide a 2D floorplan of the area being traversed by the sensor suite, as well as a real-time depth-augmented video feed.
\par
One type of technology that would be useful for performing the high speed data processing necessary for such a device is a Field Programmable Gate Array (FPGA). FPGAs pose several advantages for real-time data processing over standard computing or microcontroller technology, as they have the ability to manipulate digital information in parallel using hardware only. This allows for extremely high-speed performance; FPGA latency is mostly dependent on data inputs, as opposed to software latency which is dependent on task priority.
\par
Although FPGA technology is highly applicable to performing SLAM-like tasks, there are currently few existing commercial products that use FPGAs for this purpose. Most current SLAM implementations rely on the use of a sensor suite connected to a computer or system on chip (SoC) computing device that performs data analysis using a real-time operating system (RTOS). This setup implies that data must first be collected by a sensor suite and then transferred to an external computing device that is limited to processing the data serially based on its arrival time. Although this type of setup is acceptable for performing real-time situational awareness analysis, we proposed that an embedded FPGA-based remote mapping device would be a much more elegant and higher-speed solution.